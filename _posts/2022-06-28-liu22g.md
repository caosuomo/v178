---
title: Orthogonal Statistical Learning with Self-Concordant Loss
abstract: Orthogonal statistical learning and double machine learning have emerged
  as general frameworks for two-stage statistical prediction in the presence of a
  nuisance component. We establish non-asymptotic bounds on the excess risk of orthogonal
  statistical learning methods with a loss function satisfying a self-concordance
  property. Our bounds improve upon existing bounds by a dimension factor while lifting
  the assumption of strong convexity. We illustrate the results with examples from
  multiple treatment effect estimation and generalized partially linear modeling.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu22g
month: 0
tex_title: Orthogonal Statistical Learning with Self-Concordant Loss
firstpage: 5253
lastpage: 5277
page: 5253-5277
order: 5253
cycles: false
bibtex_author: Liu, Lang and Cinelli, Carlos and Harchaoui, Zaid
author:
- given: Lang
  family: Liu
- given: Carlos
  family: Cinelli
- given: Zaid
  family: Harchaoui
date: 2022-06-28
address:
container-title: Proceedings of Thirty Fifth Conference on Learning Theory
volume: '178'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v178/liu22g/liu22g.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
