---
title: Towards a Theory of Non-Log-Concave Sampling:First-Order Stationarity Guarantees
  for Langevin Monte Carlo
abstract: For the task of sampling from a density $\pi \propto \exp(-V)$ on $\R^d$,
  where $V$ is possibly non-convex but $L$-gradient Lipschitz, we prove that averaged
  Langevin Monte Carlo outputs a sample with $\varepsilon$-relative Fisher information
  after $O(L^2 d^2/\varepsilon^2)$ iterations. This is the sampling analogue of complexity
  bounds for finding an $\varepsilon$-approximate first-order stationary points in
  non-convex optimization and therefore constitutes a first step towards the general
  theory of non-log-concave sampling. We discuss numerous extensions and applications
  of our result; in particular, it yields a new state-of-the-art guarantee for sampling
  from distributions which satisfy a Poincar√© inequality.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: balasubramanian22a
month: 0
tex_title: Towards a Theory of Non-Log-Concave Sampling:First-Order Stationarity Guarantees
  for Langevin Monte Carlo
firstpage: 2896
lastpage: 2923
page: 2896-2923
order: 2896
cycles: false
bibtex_author: Balasubramanian, Krishna and Chewi, Sinho and Erdogdu, Murat A and
  Salim, Adil and Zhang, Shunshi
author:
- given: Krishna
  family: Balasubramanian
- given: Sinho
  family: Chewi
- given: Murat A
  family: Erdogdu
- given: Adil
  family: Salim
- given: Shunshi
  family: Zhang
date: 2022-06-28
address:
container-title: Proceedings of Thirty Fifth Conference on Learning Theory
volume: '178'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v178/balasubramanian22a/balasubramanian22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
