---
title: Risk bounds for aggregated shallow neural networks using Gaussian priors
abstract: Analysing statistical properties of neural networks  is a central topic
  in statistics and machine learning.  However, most results in the literature focus
  on the properties of the neural network minimizing the training  error. The goal
  of this paper is to consider aggregated neural networks using a Gaussian prior.
  The departure point of our approach is an arbitrary aggregate satisfying the PAC-Bayesian
  inequality. The main contribution  is a precise nonasymptotic assessment of the
  estimation error appearing in the PAC-Bayes bound. Our analysis is sharp enough
  to lead to minimax rates of estimation over Sobolev smoothness classes.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tinsi22a
month: 0
tex_title: Risk bounds for aggregated shallow neural networks using Gaussian priors
firstpage: 227
lastpage: 253
page: 227-253
order: 227
cycles: false
bibtex_author: Tinsi, Laura and Dalalyan, Arnak
author:
- given: Laura
  family: Tinsi
- given: Arnak
  family: Dalalyan
date: 2022-06-28
address:
container-title: Proceedings of Thirty Fifth Conference on Learning Theory
volume: '178'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v178/tinsi22a/tinsi22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
