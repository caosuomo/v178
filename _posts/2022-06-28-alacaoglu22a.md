---
title: Stochastic Variance Reduction for Variational Inequality Methods
abstract: We propose stochastic variance reduced algorithms for solving convex-concave
  saddle point problems, monotone variational inequalities, and monotone inclusions.
  Our framework applies to extragradient, forward-backward-forward, and forward-reflected-backward
  methods both in Euclidean and Bregman setups. All proposed methods converge in exactly
  the same setting as their deterministic counterparts and they either match or improve
  the best-known complexities for solving structured min-max problems. Our results
  reinforce the correspondence between variance reduction in variational inequalities
  and minimization. We also illustrate the improvements of our approach with numerical
  evaluations on matrix games.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: alacaoglu22a
month: 0
tex_title: Stochastic Variance Reduction for Variational Inequality Methods
firstpage: 778
lastpage: 816
page: 778-816
order: 778
cycles: false
bibtex_author: Alacaoglu, Ahmet and Malitsky, Yura
author:
- given: Ahmet
  family: Alacaoglu
- given: Yura
  family: Malitsky
date: 2022-06-28
address:
container-title: Proceedings of Thirty Fifth Conference on Learning Theory
volume: '178'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v178/alacaoglu22a/alacaoglu22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
