---
title: Parameter-free Mirror Descent
abstract: We develop a modified online mirror descent framework that is suitable for
  building adaptive and parameter-free algorithms in unbounded domains. We leverage
  this technique to develop the first unconstrained online linear optimization algorithm
  achieving an optimal dynamic regret bound, and we further demonstrate that natural
  strategies based on Follow-the-Regularized-Leader are unable to achieve similar
  results. We also apply our mirror descent framework to build new parameter-free
  implicit updates, as well as a simplified and improved unconstrained scale-free
  algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jacobsen22a
month: 0
tex_title: Parameter-free Mirror Descent
firstpage: 4160
lastpage: 4211
page: 4160-4211
order: 4160
cycles: false
bibtex_author: Jacobsen, Andrew and Cutkosky, Ashok
author:
- given: Andrew
  family: Jacobsen
- given: Ashok
  family: Cutkosky
date: 2022-06-28
address:
container-title: Proceedings of Thirty Fifth Conference on Learning Theory
volume: '178'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v178/jacobsen22a/jacobsen22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
